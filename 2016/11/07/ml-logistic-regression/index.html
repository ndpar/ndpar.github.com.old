
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Machine Learning: Logistic Regression - Side Notes</title>
  <meta name="author" content="Andrey Paramonov">

  
  <meta name="description" content="Logistic regression is a classification case of linear regression whith
dependent variable $y$ taking binary values. Problem: Given a training set $\ &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://blog.ndpar.com/2016/11/07/ml-logistic-regression">
  <link href="/favicon.ico" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/atom.xml" rel="alternate" title="Side Notes" type="application/atom+xml">

  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="./javascripts/lib/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>

  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

<!-- MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript"
   src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

  

</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">Side Notes</a></h1>
  
    <h2>never finished…</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="https://www.google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:blog.ndpar.com" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/archives">Archives</a></li>
  <li><a href="/about">About</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div>
<article class="hentry" role="article">
  
  <header>
    
      <h1 class="entry-title">Machine Learning: Logistic Regression</h1>
    
    
      <p class="meta">
        








  



<time datetime="2016-11-07T16:05:31-05:00" pubdate data-updated="true">November 07, 2016</time>
        
      </p>
    
  </header>


<div class="entry-content"><p><em>Logistic regression</em> is a classification case of <a href="/2016/10/28/ml-linear-regression">linear regression</a> whith
dependent variable $y$ taking binary values.</p>

<p>Problem: Given a training set $\langle x^{(i)}, y^{(i)} \rangle$, $1 \le i \le m$,
$x \in \mathbb{R}^{n+1}$, $x^{(i)} _ 0 = 0$, $y^{(i)} \in $ {0,1},
find <em>classification function</em></p>

<script type="math/tex; mode=display">h_\theta(x) = P(y = 1 | x; \theta)</script>

<!-- more -->

<h2 id="gradient-descent">Gradient Descent</h2>

<p>Let’s build function $h_\theta(x)$ as a sigmoid function of $\theta\cdot x$</p>

<script type="math/tex; mode=display">h_\theta(x) = g(\theta\cdot x), \quad
g(z) = \mathbb{sigmoid}(z) = \frac{1}{1 + e^{-z}}</script>

<p>Sigmoid function has rank infinity, i.e. it operates on scalars, vectors and matrices.</p>

<figure class="code"><figcaption><span>sigmoid.m </span></figcaption>
<div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
</pre></td><td class="code"><pre><code class="matlab"><span class="line"><span class="k">function</span><span class="w"> </span>g <span class="p">=</span><span class="w"> </span><span class="nf">sigmoid</span><span class="p">(</span>z<span class="p">)</span><span class="w"></span>
</span><span class="line"><span class="w">    </span><span class="n">g</span> <span class="p">=</span> <span class="mi">1</span> <span class="o">./</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="nb">exp</span><span class="p">(</span><span class="o">-</span><span class="n">z</span><span class="p">));</span>
</span><span class="line"><span class="k">end</span>
</span></code></pre></td></tr></table></div></figure>

<p>To find optimal parameter $\theta \in \mathbb{R}^{n+1}$ we are going to use
optimized gradient descent method which takes as arguments
cost function $J(\theta)$ and its gradient.
For logistic regression they are</p>

<script type="math/tex; mode=display">J(\theta) = -\frac{1}{m} \left( y^T \ln h_\theta(X) + (1-y)^T \ln (1-h_\theta(X)) \right) \\
\nabla J(\theta) = \frac{1}{m} X^T (h_\theta(X) - y)</script>

<p>where $X = (x^{(i)}_j) _{m \times n+1}$ is a matrix of the training examples from
the <a href="/2016/10/28/ml-linear-regression">previous lecture</a>.</p>

<p>Analogous to linear regression, logistic regression can be regularized too</p>

<script type="math/tex; mode=display">J(\theta) = -\frac{1}{m} \left( y^T \ln h_\theta(X) + (1-y)^T \ln (1-h_\theta(X)) \right) + \frac{\lambda}{2m} \| E\theta \|^2 \\
\nabla J(\theta) = \frac{1}{m} \left( X^T (h_\theta(X) - y) + \lambda E\theta \right)</script>

<figure class="code"><figcaption><span>costFunction.m </span></figcaption>
<div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
</pre></td><td class="code"><pre><code class="matlab"><span class="line"><span class="k">function</span><span class="w"> </span>[J, grad] <span class="p">=</span><span class="w"> </span><span class="nf">costFunction</span><span class="p">(</span>theta, X, y, lambda<span class="p">)</span><span class="w"></span>
</span><span class="line"><span class="w">    </span><span class="n">m</span> <span class="p">=</span> <span class="nb">length</span><span class="p">(</span><span class="n">y</span><span class="p">);</span> <span class="c">% number of training examples</span>
</span><span class="line">    <span class="n">h</span> <span class="p">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">X</span> <span class="o">*</span> <span class="n">theta</span><span class="p">);</span>
</span><span class="line">    <span class="n">J</span> <span class="p">=</span> <span class="p">(</span><span class="n">y</span><span class="o">&#39;</span> <span class="o">*</span> <span class="nb">log</span><span class="p">(</span><span class="n">h</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">y</span><span class="p">)</span><span class="o">&#39;</span> <span class="o">*</span> <span class="nb">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">h</span><span class="p">))</span> <span class="o">/</span> <span class="o">-</span><span class="n">m</span><span class="p">;</span>
</span><span class="line">    <span class="n">grad</span> <span class="p">=</span> <span class="n">X</span><span class="o">&#39;</span> <span class="o">*</span> <span class="p">(</span><span class="n">h</span> <span class="o">-</span> <span class="n">y</span><span class="p">)</span> <span class="o">/</span> <span class="n">m</span><span class="p">;</span>
</span><span class="line">
</span><span class="line">    <span class="c">% Regularization</span>
</span><span class="line">    <span class="n">th</span> <span class="p">=</span> <span class="n">theta</span><span class="p">;</span> <span class="n">th</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="p">=</span> <span class="mi">0</span><span class="p">;</span>
</span><span class="line">
</span><span class="line">    <span class="n">J</span> <span class="p">=</span> <span class="n">J</span> <span class="o">+</span> <span class="n">th</span><span class="o">&#39;</span> <span class="o">*</span> <span class="n">th</span> <span class="o">*</span> <span class="n">lambda</span> <span class="o">/</span> <span class="n">m</span> <span class="o">/</span> <span class="mi">2</span><span class="p">;</span>
</span><span class="line">    <span class="n">grad</span> <span class="p">=</span> <span class="n">grad</span> <span class="o">+</span> <span class="n">th</span> <span class="o">*</span> <span class="n">lambda</span> <span class="o">/</span> <span class="n">m</span><span class="p">;</span>
</span><span class="line"><span class="k">end</span>
</span></code></pre></td></tr></table></div></figure>

<p>Having computed $\theta$ we can now implement the prediction function</p>

<figure class="code"><figcaption><span>predict.m </span></figcaption>
<div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
</pre></td><td class="code"><pre><code class="matlab"><span class="line"><span class="k">function</span><span class="w"> </span>p <span class="p">=</span><span class="w"> </span><span class="nf">predict</span><span class="p">(</span>theta, X<span class="p">)</span><span class="w"></span>
</span><span class="line"><span class="w">    </span><span class="n">p</span> <span class="p">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">X</span> <span class="o">*</span> <span class="n">theta</span><span class="p">)</span> <span class="o">&gt;</span><span class="p">=</span> <span class="mf">0.5</span><span class="p">;</span>
</span><span class="line"><span class="k">end</span>
</span></code></pre></td></tr></table></div></figure>

<p>which can be used to classify new examples and check the prediction accuracy
on the training set</p>

<figure class="code"><figcaption><span>accuracy.m </span></figcaption>
<div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
</pre></td><td class="code"><pre><code class="matlab"><span class="line"><span class="k">function</span><span class="w"> </span>a <span class="p">=</span><span class="w"> </span><span class="nf">accuracy</span><span class="p">(</span>theta, X, y<span class="p">)</span><span class="w"></span>
</span><span class="line"><span class="w">    </span><span class="n">p</span> <span class="p">=</span> <span class="n">predict</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">X</span><span class="p">);</span>
</span><span class="line">    <span class="n">a</span> <span class="p">=</span> <span class="n">mean</span><span class="p">(</span><span class="n">double</span><span class="p">(</span><span class="n">p</span> <span class="o">==</span> <span class="n">y</span><span class="p">))</span> <span class="o">*</span> <span class="mi">100</span><span class="p">;</span>
</span><span class="line"><span class="k">end</span>
</span></code></pre></td></tr></table></div></figure>

<h2 id="multi-class-classification">Multi-class Classification</h2>

<p>Logistic regression works for binary $y$.
Suppose now that $y^{(i)} \in ${$1,…,K$}, where $K &gt; 2$.
In this case we can use <em>One-vs-All</em> variation of this algorithm.</p>

<p>Step 1. Convert vector $y$ into a binary matrix $Y$</p>

<script type="math/tex; mode=display">% <![CDATA[
y =
\begin{pmatrix}
y^{(1)} \\
y^{(2)} \\
y^{(3)} \\
\vdots \\
y^{(m)} \\
\end{pmatrix}
\quad
\rightarrow
\quad
Y =
\begin{pmatrix}
y^{(1)}_1 & y^{(1)}_2 & \cdots & y^{(1)}_K \\
y^{(2)}_1 & y^{(2)}_2 & \cdots & y^{(2)}_K \\
y^{(3)}_1 & y^{(3)}_2 & \cdots & y^{(3)}_K \\
\vdots & \vdots & \ddots & \vdots \\
y^{(m)}_1 & y^{(m)}_2 & \cdots & y^{(m)}_K \\
\end{pmatrix} %]]></script>

<p>where $y^{(i)}_k = \delta _{k y^{(i)}}$, i.e. $y^{(i)}_k = 1$ when $y^{(i)} = k$, otherwise $y^{(i)}_k = 0$.</p>

<p>Step 2. Train logistic classifier on every column of matrix $Y$.
The result will be a matrix $\Theta = (\theta_{jk})_{n+1 \times K}$</p>

<script type="math/tex; mode=display">% <![CDATA[
\Theta =
\begin{pmatrix}
\theta_{01} & \theta_{02} & \cdots & \theta_{0K} \\
\theta_{11} & \theta_{12} & \cdots & \theta_{1K} \\
\theta_{21} & \theta_{22} & \cdots & \theta_{2K} \\
\vdots & \vdots & \ddots & \vdots \\
\theta_{n1} & \theta_{n2} & \cdots & \theta_{nK} \\
\end{pmatrix} %]]></script>

<p>Step 3. For any given vector $x$ compute vector $h = x^T \Theta$. Then
the predicted value $y$ will be</p>

<script type="math/tex; mode=display">y = \{ p \: | \: h_p = \mathbb{max} (h_k), 1 \le k \le K \}</script>

<p>To compute accuracy of the one-vs-all classifier on the training set
use <code>accuracy.m</code> script from above with modified <code>predict.m</code></p>

<figure class="code"><figcaption><span>predict.m </span></figcaption>
<div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
</pre></td><td class="code"><pre><code class="matlab"><span class="line"><span class="k">function</span><span class="w"> </span>p <span class="p">=</span><span class="w"> </span><span class="nf">predict</span><span class="p">(</span>Theta, X<span class="p">)</span><span class="w"></span>
</span><span class="line"><span class="w">    </span><span class="n">a</span> <span class="p">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">X</span> <span class="o">*</span> <span class="n">Theta</span><span class="p">);</span>
</span><span class="line">    <span class="p">[</span><span class="n">v</span><span class="p">,</span> <span class="n">p</span><span class="p">]</span> <span class="p">=</span> <span class="n">max</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="p">[],</span> <span class="mi">2</span><span class="p">);</span>
</span><span class="line"><span class="k">end</span>
</span></code></pre></td></tr></table></div></figure>

</div>


  <footer>
    <p class="meta">
      
  

<span class="byline author vcard">Posted by <span class="fn">Andrey Paramonov</span></span>

      








  



<time datetime="2016-11-07T16:05:31-05:00" pubdate data-updated="true">November 07, 2016</time>
      

<span class="categories">
  
    <a class='category' href='/categories/machine-learning/'>machine learning</a>, <a class='category' href='/categories/math/'>math</a>, <a class='category' href='/categories/matlab/'>matlab</a>
  
</span>


    </p>
    
      <div class="sharing">
  
  
  
</div>

    
    <p class="meta">
      
        <a class="basic-alignment left" href="/2016/10/28/ml-linear-regression/" title="Previous Post: Machine Learning: Linear Regression">&laquo; Machine Learning: Linear Regression</a>
      
      
        <a class="basic-alignment right" href="/2016/12/24/spring-oauth2/" title="Next Post: Spring OAuth 2">Spring OAuth 2 &raquo;</a>
      
    </p>
  </footer>
</article>

</div>

<aside class="sidebar">
  
    <section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/2016/12/24/spring-oauth2/">Spring OAuth 2</a>
      </li>
    
      <li class="post">
        <a href="/2016/11/07/ml-logistic-regression/">Machine Learning: Logistic Regression</a>
      </li>
    
      <li class="post">
        <a href="/2016/10/28/ml-linear-regression/">Machine Learning: Linear Regression</a>
      </li>
    
      <li class="post">
        <a href="/2015/04/03/feynman-tot/">Another Notation as a Tool of Thought</a>
      </li>
    
      <li class="post">
        <a href="/2014/11/29/two-series/">Two Series</a>
      </li>
    
  </ul>
</section>


<section>
  <h1>Recent GitHub Updates</h1>
  <ul id="gh_repos">
    <li class="loading">Status updating...</li>
  </ul>
  
  <script type="text/javascript">
    $(document).ready(function(){
        if (!window.jXHR){
            var jxhr = document.createElement('script');
            jxhr.type = 'text/javascript';
            jxhr.src = '/javascripts/libs/jXHR.js';
            var s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(jxhr, s);
        }

        github.showRepos({
            user: 'ndpar',
            count: 4,
            skip_forks: false,
            target: '#gh_repos'
        });
    });
  </script>
  <script src="/javascripts/github.js" type="text/javascript"> </script>
</section>




<section>
  <h1>Categories</h1>
  <ul id="categories">
    <li class='category'><a href='/categories/activemq/'>activemq (1)</a></li>
<li class='category'><a href='/categories/agile/'>agile (1)</a></li>
<li class='category'><a href='/categories/art/'>art (1)</a></li>
<li class='category'><a href='/categories/book-review/'>book review (1)</a></li>
<li class='category'><a href='/categories/buzz/'>buzz (2)</a></li>
<li class='category'><a href='/categories/clojure/'>clojure (4)</a></li>
<li class='category'><a href='/categories/clustering/'>clustering (1)</a></li>
<li class='category'><a href='/categories/conference/'>conference (3)</a></li>
<li class='category'><a href='/categories/craftsmanship/'>craftsmanship (1)</a></li>
<li class='category'><a href='/categories/education/'>education (1)</a></li>
<li class='category'><a href='/categories/ejabberd/'>ejabberd (2)</a></li>
<li class='category'><a href='/categories/entrepreneurship/'>entrepreneurship (1)</a></li>
<li class='category'><a href='/categories/erlang/'>erlang (8)</a></li>
<li class='category'><a href='/categories/feynman/'>feynman (1)</a></li>
<li class='category'><a href='/categories/functional-programming/'>functional programming (1)</a></li>
<li class='category'><a href='/categories/git/'>git (3)</a></li>
<li class='category'><a href='/categories/grails/'>grails (1)</a></li>
<li class='category'><a href='/categories/groovy/'>groovy (10)</a></li>
<li class='category'><a href='/categories/haskell/'>haskell (1)</a></li>
<li class='category'><a href='/categories/humor/'>humor (2)</a></li>
<li class='category'><a href='/categories/j/'>j (2)</a></li>
<li class='category'><a href='/categories/java/'>java (4)</a></li>
<li class='category'><a href='/categories/lisp/'>lisp (3)</a></li>
<li class='category'><a href='/categories/machine-learning/'>machine learning (2)</a></li>
<li class='category'><a href='/categories/math/'>math (11)</a></li>
<li class='category'><a href='/categories/matlab/'>matlab (2)</a></li>
<li class='category'><a href='/categories/maven/'>maven (1)</a></li>
<li class='category'><a href='/categories/mongodb/'>mongodb (1)</a></li>
<li class='category'><a href='/categories/nosql/'>nosql (1)</a></li>
<li class='category'><a href='/categories/oauth/'>oauth (1)</a></li>
<li class='category'><a href='/categories/programming/'>programming (6)</a></li>
<li class='category'><a href='/categories/python/'>python (2)</a></li>
<li class='category'><a href='/categories/rabbitmq/'>rabbitmq (4)</a></li>
<li class='category'><a href='/categories/regex/'>regex (2)</a></li>
<li class='category'><a href='/categories/scala/'>scala (1)</a></li>
<li class='category'><a href='/categories/sicp/'>sicp (1)</a></li>
<li class='category'><a href='/categories/solr/'>solr (1)</a></li>
<li class='category'><a href='/categories/spring/'>spring (2)</a></li>
<li class='category'><a href='/categories/tutorial/'>tutorial (1)</a></li>
<li class='category'><a href='/categories/zeromq/'>zeromq (1)</a></li>
<li class='category'><a href='/categories/zookeeper/'>zookeeper (1)</a></li>

  </ul>
</section>

  
</aside>


    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2009–2017 - Andrey Paramonov -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span> -
  <span class="credit">Hosted by <a href="http://github.com">GitHub</a></span>
</p>

</footer>
  











</body>
</html>
